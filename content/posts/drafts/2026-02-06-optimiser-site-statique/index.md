---
date: 2026-02-06
title: Optimiser un site Hugo
draft: true
---

[//]: # (TODO link vers le blog d'antoine)
Sur les bons conseils du pote Antoine Caron, j'ai pris temps cette semaine d'optimiser un peu mon site.

Ce site que vous √™tes en train de lire est un site statique, build√© avec Hugo.

J'ai d√©j√† un peu travaill√© la compression des diff√©rentes ressources, principalement les illustrations, mais je m'√©tais arr√™t√© √† √ßa.
Dans cet article, je d√©taille comment j'ai optimis√© le build de ce site, pour minimiser les temps de chargement, et comment j'ai am√©lior√© sa s√©curit√© en suivant les bonnes pratiques pouss√©es par MDN.

## Le score Lighthouse

Pour faire un premier travail sur les performances de ce site, j'ai utilis√© [une analyse LightHouse](https://pagespeed.web.dev/analysis/https-codeka-io/we5dukzmku?form_factor=desktop).

Lighthouse permet en quelques minutes d'avoir une vue des performances d'une application ou d'un site web, √† la fois pour une cible _Desktop_ et _Mobile_.
Il permet aussi de valider certaines propri√©t√©s d'accessibilit√©, comme des contrastes, la pr√©sence de texte alternatif pour les lecteurs d'√©cran, etc.

C'est, je pense, un bon point de d√©part.

Voici les scores de mon site √† l'heure actuelle :


![Score Lighthouse pour un mobile](lighthouse-mobile.png)
![Score Lighthouse pour un desktop](lighthouse-desktop.png)


> J'ai clairement une marge d'am√©lioration sur l'accessibilit√© et les performances.

## Minification

Une premi√®re √©tape consiste √† minifier les ressources statiques, HTML, CSS et JS.

Cette √©tape est tr√®s simple √† mettre en place, car elle est d√©j√† support√©e par Hugo.
Il suffit lors du build d'ajouter le flag `--minify` pour demander √† Hugo de minifier toutes les ressources.

Ma commande de build est la suivante dans mon `mise.toml` :

```toml
[tasks.build]
description = "Build le site avec Hugo"
run = "hugo --gc --minify --destination public"
```

Ce qui produit des fichiers HTML minifi√©s de ce type :

```html
<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=fr-FR lang=fr-FR><head><script defer language=javascript type=text/javascript src=/js/bundle.min.39a1898ad60dcb3b845d8dc359b7c996c10aa0da902f0d461da32348b1bc5f02.js></script><script defer data-domain=codeka.io src=https://plausible.io/js/script.js></script><script type=text/javascript src=https://app.affilizz.com/affilizz.js async></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=icon href=/favicon.png><meta property="og:image" content="/pp_ekite_itvw.png"><meta name=twitter:image content="/pp_ekite_itvw.png"><meta name=twitter:card content="summary_large_image"><meta property="og:image:width" content="639"><meta property="og:image:height" content="708"><meta property="og:image:type" content="image/png"><title itemprop=name>Julien Wittouck</title><meta property="og:title" content="Julien Wittouck"><meta name=twitter:title content="Julien Wittouck"><meta itemprop=name content="Julien Wittouck"><meta name=application-name content="Julien Wittouck"><meta property="og:site_name" content="Julien Wittouck">
```

Hop, on peut passer rapidement √† autre chose üö∂

## Conversion des images en webp et redimensionnement

Une des actions que j'ai mis en place il y a un moment, est l'utilisation du format _webp_ pour compresser les illustrations que j'utilise dans mes articles.

J'utilise souvent des photos que j'ai captur√©es avec mon smartphone (pour les articles de conf√©rence), des captures d'√©cran ou des sch√©mas (produit sur draw.io le plus souvent), ou des photos _stock_ que je vais chercher pour illustrer mes articles de veille.

Ces photos sont souvent lourdes (plusieurs m√©gaoctets) et en haute r√©solution, et la premi√®re action simple consiste √† redimensionner ces photo et les recompresser au format _webp_.

Hugo supporte la recompression des images dans diff√©rents formats √† la vol√©e, mais pas leur redimensionnement automatique, il faut impl√©menter soi-m√™me la m√©canique.
Pour pouvoir redimensionner les images √† la vol√©e, la meilleure solution semble d'utiliser un hook "img" Hugo, qui permet de surcharger la traduction du markdown et d'y mettre le code qu'on souhaite.

Le hook utilis√© par d√©faut est le suivant :

```go
<img src="{{ .Destination | safeURL }}"
  {{- with .PlainText }} alt="{{ . }}"{{ end -}}
  {{- with .Title }} title="{{ . }}"{{ end -}}
>
{{- /* chomp trailing newline */ -}}
```

Pour redimensionner les images √† une taille maximale de 820px (la taille utilis√©e sur la colonne de contenu de ce site), j'utilise le hook suivant :

```go
{{- $image := .Page.Resources.GetMatch .Destination -}}
{{- $width := math.Min 820 $image.Width -}}
{{- $resizeOpts := printf "%dx webp lossless q100 lanczos" (int $width) -}}
{{- with $image.Resize $resizeOpts -}}
<img src="{{ .RelPermalink }}" width="{{ .Width }}" height="{{ .Height }}"
    {{- with $.PlainText }} alt="{{ . }}"{{ end -}}
    {{ with $.Title }}title="{{ . }}"{{ end }}>
{{- end -}}
{{- /* chomp trailing newline */ -}}
```

Je force l'utilisation de `lossless` avec la qualit√© maximale `q100` pour √©viter une perte de donn√©es qui rendrait les illustations peu lisible, ce qui serait surtout probl√©matique pour les sch√©mas.

## Pr√©-compression des ressources statiques

Les images √©tant maintenant compress√©es au build par Hugo, je peux m'atteler √† la compression des ressources d√©j√† minifi√©es (HTML, CSS et JS donc).

Avant de passer √† la pr√©-compression en elle-m√™me, il faut regarder comment les ressources seront servies.

Mon site est h√©berg√© chez Clever Cloud, dans une instance de type _static_.
J'avais √©crit un article √† ce sujet l'ann√©e derni√®re : [D√©ployer des applications statiques sur Clever Cloud](/2025/06//2025-06-05-static-apps-clever).

Clever Cloud permet d'utiliser Caddy pour servir les fichiers statiques en surcharge de `static-web-server`, simplement en ajoutant un `Caddyfile` √† la racine du projet.

Cette option va me permettre de pouvoir configurer Caddy pour servir le r√©pertoire `public` du site :

```Caddyfile
# Clever Cloud needs us to listen on port 8080
:8080

file_server {
	# Clever Cloud serves the public directory in a cc_static_autobuilt directory
    root public
}

# Ask Caddy to compress static files 
encode
```

Lors de l'ex√©cution d'une requ√™te, Caddy va servir les fichiers statiques, et potentiellement compresser les r√©ponses HTTP en alimentant le headers `Content-Encoding`. Les formats utilis√©s par d√©faut par Caddy sont `zstd` et `gzip`, et seules les ressources pertinentes sont compress√©es (les formats d√©j√† compress√©s comme `jpg` ne sont pas re-compress√©s).

Cette compression permet d'√©conomiser de la bande passante et acc√©l√®re le temps de chargement des pages.

Cependant, la compression se fait en utilisant un peu de CPU √† la vol√©e.
Il est alors int√©ressant de pr√©-compresser les ressources statiques √† la phase de build pour √©conomiser un peu de CPU.

Une directive Caddy permet de servir des fichiers statiques pr√©-compress√©s : `precompressed`.
Caddy va alors rechercher des variantes compress√©es des fichiers, sous la forme de fichiers sidecar.
√Ä c√¥t√© de chaque fichier statique, il faut donc g√©n√©rer les variantes compress√©es et les nommer en utilisant les extensions `.gz`, `.br` et `.zst` par exemple.

Hugo ne permet pas de g√©n√©rer ces variantes compress√©es de lui-m√™me, donc je dois utiliser un petit script qui s'ex√©cutera en fin de la phase de build.

J'ai donc cr√©√© ce script dans mon fichier `mise.toml` :

```toml
[tasks.build]
description = "Build le site avec Hugo"
run = "hugo --gc --minify --destination public"

[tasks.post-build]
description = "Post build hooks"
depends_post = ["precompress"]

[tasks.precompress]
description = "Precompress static resources"
run = '''
COMPRESSREGEX=".*(html|css|js|xml|ico|svg|md|pdf|woff2)$"
find public/ -type f -regextype egrep -regex $COMPRESSREGEX | xargs zstd --keep --force -19
find public/ -type f -regextype egrep -regex $COMPRESSREGEX | xargs gzip --keep  --force --best
'''
```

J'ai impl√©ment√© la compression avec `gzip` en utilisant le plus haut niveau de compression possible (`--best`), et avec `zstd` avec la plus forte compression √©galement (`-19`). Le niveau de compression a surtout un impact √† la compression, mais peu √† la d√©compression, donc autant maximiser les diff√©rents niveaux.
J'ai fait l'impasse sur le format `br` parce qu'il n√©cessite d'installer un binaire suppl√©mentaire sur mes instances Clever Cloud, et que `gz` et `zst` sont d√©j√† bien suffisants : `zst` sera support√© par les navigateurs modernes dans les versions les plus r√©centes, `gzip` fera office de format par d√©faut raisonnable.

Par d√©faut, Clever Cloud ex√©cute une t√¢che `mise run build` si elle existe, donc l'ajouter dans mon fichier permet de pouvoir pr√©ciser mes options de build.

Pour la phase de compression, il suffit d'indiquer √† Clever Cloud d'ex√©cuter `mise run post-build`, cela se fait avec un hook sur 

Le script `precompress` est inspir√© d'un [article de blog de Scott Laird](https://scottstuff.net/posts/2025/03/09/precompressing-content-with-hugo-and-caddy/) sur lequel je suis tomb√© en faisant quelques recherches.
Il recherche l'ensemble des fichiers matchant la regex donn√©e, et utilise `zstd` pour compresser ces fichiers.

L'ex√©cution de ces scripts produit la sortie suivante : 

```bash
[build] $ hugo build hugo --gc --minify --destination public
Start building sites ‚Ä¶
hugo v0.155.2-d8c0dfccf72ab43db2b2bca1483a61c8660021d9+extended linux/amd64 BuildDate=2026-02-02T10:04:51Z VendorInfo=gohugoio

                  ‚îÇ EN ‚îÇ FR
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
 Pages            ‚îÇ 75 ‚îÇ 139
 Paginator pages  ‚îÇ  0 ‚îÇ   4
 Non-page files   ‚îÇ 14 ‚îÇ 222
 Static files     ‚îÇ 36 ‚îÇ  36
 Processed images ‚îÇ  3 ‚îÇ 275
 Aliases          ‚îÇ  1 ‚îÇ   8
 Cleaned          ‚îÇ  0 ‚îÇ   0

Total in 272 ms
[precompress] $ COMPRESSREGEX=".*(html|css|js|xml|ico|svg|md|pdf|woff2)$"
245 files compressed : 80.99% (  83.3 MiB =>   67.4 MiB)                       B ==> 98%^T
Finished in 7.77s
```

On peut valider que les fichiers build√©s sont pr√©compress√©s comme souhait√©, avec les extensions `.gz` et `.zst` :

```bash
$ ls public/
2020         404.html.zst  fonts           index.xml.zst                           projects
2021         ai            fr              js                                      robots.txt
2022         ai-manifesto  icons           logo_blue.png                           series
2023         books         images          logo_transparent_background.png         sitemap.xml
2024         credentials   index.html      now                                     sitemap.xml.gz
2025         css           index.html.gz   page                                    sitemap.xml.zst
2026         ekite         index.html.zst  posts                                   stats
404.html     en            index.xml       pp_ekite_itvw.png                       tags
404.html.gz  favicon.png   index.xml.gz    pp_ekite_itvw_hu_41404e93ad715bdf.webp  talks
```

et v√©rifier la taille des fichiers compress√©s :

```bash
$ ls -al public/index.*
.rw-rw-r-- jwittouck jwittouck  33 KB Wed Feb 11 12:15:21 2026 index.html
.rw-rw-r-- jwittouck jwittouck 9.4 KB Wed Feb 11 12:15:21 2026 index.html.gz
.rw-rw-r-- jwittouck jwittouck 9.0 KB Wed Feb 11 12:15:21 2026 index.html.zst
.rw-rw-r-- jwittouck jwittouck  67 KB Wed Feb 11 12:15:22 2026 index.xml
.rw-rw-r-- jwittouck jwittouck  18 KB Wed Feb 11 12:15:22 2026 index.xml.gz
.rw-rw-r-- jwittouck jwittouck  17 KB Wed Feb 11 12:15:22 2026 index.xml.zst
```

Pour ensuite servir les fichiers pr√©compress√©s, il faut ajouter la [directive `precompressed`](https://caddyserver.com/docs/caddyfile/directives/file_server#precompressed) dans le `Caddyfile` :

```Caddyfile
# Clever Cloud needs us to listen on port 8080
:8080

file_server {
	# Clever Cloud serves the public directory
    root public
    # serve precompressed files
    precompressed
}

# Ask Caddy to compress static files 
encode
```

La directive `precompressed` recherchera dans l'ordre les fichiers `.zst` et `.gz` pour les servir en priorit√©, et utilisera comme _fallback_ une compression √† la vol√©e.

On peut ensuite simplement v√©rifier que les fichiers compress√©s sont bien servis compress√©s avec une commande `curl`.

Voici ce qui √©tait renvoy√© _avant_ la compression :

```bash
$ curl --head https://codeka.io

Content-Length: 81157
Content-Type: text/html; charset=utf-8
Server: Caddy
```

et la m√™me commande apr√®s la compression :

```bash
$ curl --compressed --head https://codeka.io

HTTP/1.1 200 OK
Content-Encoding: zstd
Content-Type: text/html; charset=utf-8
Server: Caddy
Content-Length: 9
```

[//]: # (TODO) rev√©rifier apr√®s le d√©ploiement

On passe d'une page HTML de 81ko √† une donn√©e compress√©e de 13ko, sans impacter le CPU du serveur puisque la compression se fait au build !

## Headers de s√©curit√©

La derni√®re √©tape de cette configuration consiste √† moderniser les headers servis pour impl√©ments un peu de s√©curit√© suppl√©mentaire.

Maintenant que Caddy sert le site et que j'ai un Caddyfile sur lequel j'ai la main, je peux contr√¥ler les headers HTTP renvoy√©s.

Pour savoir quoi faire, sur les conseils d'Antoine, j'ai utilis√© l'analyseur de MDN :

https://developer.mozilla.org/en-US/observatory/analyze?host=codeka.io#scoring

![R√©sultat de l'analyse de MDN](mdn-analysis.png "R√©sultat de l'analyse de MDN")

### HSTS

Le premier header int√©ressant √† utiliser est le `Strict-Transport-Security`.

Ce header a pour effet de forcer les navigateurs √† utiliser HTTPS.
Bien que j'ai d√©j√† configur√© une redirection HTTP vers HTTPS sur mon domaine avec Clever Cloud, c'est une mesure de s√©curit√© suppl√©mentaire.

La recommandation de MDN est de positionner cette valeur :

```HTTP
Strict-Transport-Security: max-age=63072000
```

Dans mon Caddyfile, rien de plus simple, j'ajoute le header `Strict-Transport-Security` :

```Caddyfile
# Clever Cloud needs us to listen on port 8080
:8080

file_server {
	# Clever Cloud serves the public directory
    root public
    precompressed
}

# Custom headers for security
header {
	Strict-Transport-Security "max-age=63072000"
}

# Ask Caddy to compress static files 
encode
```

### Content-Security-Policy

Le premier header int√©ressant √† utiliser est le `Content-Security-Policy`.
Ce header indique au navigateur quelle politique de s√©curit√© appliquer √† l'ex√©cution des scripts provenant de sources externes au site web.
C'est une mesure de s√©curit√© permettant de se pr√©munir des injections de type XSS (Cross-Site Scripting).

Le header doit d√©clarer l'ensemble des sources (domaines) accept√©s pour le chargement des scripts, styles, images et autres ressources.
Utiliser ce header a aussi pour effet de d√©sactiver le CSS et le JS "inline", ce qui est plut√¥t une bonne pratique.

Apr√®s avoir supprim√© tous les styles inlines de mon site, j'ai configur√© le header dans mon Caddyfile :

```Caddyfile
# Clever Cloud needs us to listen on port 8080
:8080

file_server {
	# Clever Cloud serves the public directory
    root public
    precompressed
}

# Custom headers for security
header {
	Strict-Transport-Security "max-age=63072000"
	
    Content-Security-Policy "
	    script-src 'self' codeka.io plausible.io;
	    frame-src 'self' plausible.io www.youtube-nocookie.com openfeedback.io;
        img-src 'self' img.shields.io;
	    default-src 'self';
	"
}

# Ask Caddy to compress static files 
encode
```

J'utilise plausible.io pour suivre les visites de mes articles, donc son script doit pouvoir √™tre charg√©. De la m√™me mani√®re, j'ai des iframes (bouh) sur les pages de mes talks qui r√©f√©rencent les videos Youtube ainsi que les feedbacks OpenFeedback.io. Je dois donc aussi autoriser ces ressources.

La directive `default-src` sert de fallback pour toutes les directives possibles, et indique que seul mon site est autoris√©. 

## Conclusion

√áa m'a pris une bonne demi-journ√©e pour mettre en place tous ces m√©canismes, mais j'en ressort avec une meilleure compr√©hension de la s√©curit√© et de la compression en HTTP.
J'ai aussi d√©couvert Caddy, et am√©lior√© mon fichier `mise.toml`.

Pour la plupart de mes lecteurs, l'impact de la compression sera probablement minime, car sur des r√©seaux performants, la diff√©rence de temps de chargement ne se ressentira peut-√™tre pas beaucoup.
Mais avec une compression effectu√©e uniquement au build, c'est aussi une du CPU de moins de consomm√©, ce qui devrait pouvoir m'assurer de rester sur des instances les plus petites pour mon site le plus longtemps possible.

## Liens et r√©f√©rences

* Configuration de l'optimisation des images avec Hugo : https://gohugo.io/configuration/imaging/#quality
* La m√©thode [Resize de Hugo](https://gohugo.io/methods/resource/resize/)
* [Le hookimage de Hugo](https://gohugo.io/render-hooks/images/#article)

* Documentation de Caddy :
  * [La directive `encode`](https://caddyserver.com/docs/caddyfile/directives/encode#syntax)
  * [La directive `precompressed`](https://caddyserver.com/docs/caddyfile/directives/file_server#precompressed)

* Documentation MDN :
  * [Content-Security-Policy](https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Content-Security-Policy)

* [Precompressing Content With Hugo and Caddy](https://scottstuff.net/posts/2025/03/09/precompressing-content-with-hugo-and-caddy/)

* L'excellent talk de Antoine Caron et Hubert Sabloni√®re : [La compression Web : comment (re)prendre le contr√¥le ?](https://www.youtube.com/watch?v=LWd0hr6ljZk)