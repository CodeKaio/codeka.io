---
date: 2026-02-20
title: Optimiser les perfs et la s√©curit√© d'un site Hugo
tags:
  - clevercloud
  - security
  - devops
  - tools
---

Sur les bons conseils du pote [Antoine Caron](https://blog.slashgear.dev/), j'ai pris temps cette semaine d'optimiser un peu mon site.

Ce site que vous √™tes en train de lire est un site statique, build√© avec Hugo.

J'avais d√©j√† un peu travaill√© la compression des diff√©rentes ressources, principalement les illustrations, mais je m'√©tais arr√™t√© √† √ßa.
Dans cet article, je d√©taille comment j'ai optimis√© le build de ce site, pour minimiser les temps de chargement, et comment j'ai am√©lior√© sa s√©curit√© en suivant les bonnes pratiques pouss√©es par MDN.

<!-- more -->

## Le score Lighthouse

Pour faire un premier travail sur les performances de ce site, j'ai utilis√© [une analyse LightHouse](https://pagespeed.web.dev/analysis/https-codeka-io/we5dukzmku?form_factor=desktop) (assez classique).

Lighthouse permet en quelques minutes d'avoir une vue des performances d'une application ou d'un site web, √† la fois pour une cible _Desktop_ et _Mobile_.
Il permet aussi de valider certaines propri√©t√©s d'accessibilit√©, comme des contrastes, la pr√©sence de texte alternatif pour les lecteurs d'√©cran, etc.

C'est, je pense, un bon point de d√©part.

Voici les scores de mon site √† l'heure actuelle, pour une navigation mobile et desktop :

![Score Lighthouse pour un mobile](lighthouse-mobile.webp)
![Score Lighthouse pour un desktop](lighthouse-desktop.webp)
{ class="images-grid-2" }

Ces scores peuvent sembler int√©ressants sur la page d'accueil, mais ils se d√©gradent fortement sur certaines pages.
Voici les scores pour la page de mon talk sur Factorio :

![Score Lighthouse sur mobile pour une autre page](lighthouse-talk-mobile.webp)
![Score Lighthouse sur desktop pour une autre page](lighthouse-talk-desktop.webp)
{ class="images-grid-2" }

> J'ai clairement une marge d'am√©lioration sur l'accessibilit√© et les performances. √áa va pas du tout l√†.

Sans rentrer dans le d√©tail et l'analyse de ce qui est remont√© par cet outil, on va tout de suite s'attaquer au vif du sujet.

## Minification des HTML, CSS et JS.

Une premi√®re √©tape consiste √† minifier les ressources statiques, HTML, CSS et JS.

Cette √©tape est tr√®s simple √† mettre en place, car elle est d√©j√† support√©e par Hugo.
Il suffit lors du build d'ajouter le flag `--minify` pour demander √† Hugo de minifier toutes les ressources.

Ma commande de build est la suivante dans mon `mise.toml` :

```toml
[tasks.build]
description = "Build le site avec Hugo"
run = "hugo --gc --minify --destination public"
```

Ce qui produit des fichiers HTML minifi√©s de ce type :

![Mon fichier index.html minifi√©](index-html-minified.webp "Mon fichier index.html minifi√©")

Pas de surprise ni de difficult√© sur cette premi√®re partie, hop, on peut passer rapidement √† autre chose üö∂

> J'ai mis cette partie √† titre d'exhaustivit√©, mes ressources statiques √©taient d√©j√† minifi√©es. Mais je voulais avoir une approche compl√®te, et aussi v√©rifier ce point.

## Conversion des images en webp

J'utilise souvent des photos que j'ai captur√©es avec mon smartphone (pour les articles de conf√©rence), des captures d'√©cran ou des sch√©mas (produit sur draw.io le plus souvent), ou des photos _stock_ que je vais chercher pour illustrer mes articles de veille.

Ces photos sont souvent lourdes (plusieurs m√©gaoctets) et en haute r√©solution, et une action simple consiste √† redimensionner ces photo et les recompresser au format _webp_ ou _avif_.

Ne sachant pas trop quel format utiliser, j'ai opt√© pour _webp_ pour deux raisons : Hugo supporte le [format _webp_ nativement](https://gohugo.io/functions/images/process/#format) (pas le _avif_) et le support de _avif_ semblait un peu inf√©rieur √† _webp_ sur les navigateurs.

> Il n'est pas impossible que je change d'avis sur ce point rapidement, et que je bascule sur _avif_ d√®s que Hugo le supporte.

J'ai donc commenc√© par convertir mes illustrations en _webp_.
J'ai fait √ßa en one-shot avec un script et le CLI `cwebp` pour Linux :

```shell
# parall√©lisation des conversions pour utiliser tous les CPU disponibles
JOBS="$(nproc)"
# recherche des images
find . -type f -iname '*.jpg' -o -iname '*.jpeg' -o -iname '*.png' \
# conversion en webp
  | xargs -n 1 -P "$JOBS" -I IMG sh -c 'cwebp -q 75 IMG -o $(echo "IMG" | sed "s/\.[^.]*$/.webp/")'
```

Puis un gros `sed` pour remplacer les r√©f√©rences dans mes markdown :

```shell
sed -Ei 's/\.(jpe?g|png)$/\.webp/I' **/*.md

find . -type f -iname '*.jpg' -o -iname '*.jpeg' -o -iname '*.png' | rm
```

Les images sont maintenant en format _webp_, ce qui va me faire gagner un peu de place, et du temps de t√©l√©chargement pour les lecteurs.

Je n'ai pas fait le calcul de la r√©duction de taille, mais sur les images sources, on ne doit pas √™tre loin des 60% de leur taille d'origine :

```shell
‚ùØ ls -alh
.rw-r--r-- jwittouck jwittouck  65 KB Tue Dec 30 12:17:33 2025 clever-addon-create.png
.rw-rw-r-- jwittouck jwittouck  20 KB Fri Feb 20 10:28:43 2026 clever-addon-create.webp
.rw-r--r-- jwittouck jwittouck  69 KB Tue Dec 30 12:17:33 2025 clever-env.png
.rw-rw-r-- jwittouck jwittouck  26 KB Fri Feb 20 10:28:43 2026 clever-env.webp
.rw-r--r-- jwittouck jwittouck  48 KB Tue Dec 30 12:17:33 2025 clever-open-starting.png
.rw-rw-r-- jwittouck jwittouck  15 KB Fri Feb 20 10:28:43 2026 clever-open-starting.webp
```

## Redimensionnement aux tailles souhait√©es

Hugo supporte la recompression des images dans diff√©rents formats √† la vol√©e (qui aurait pu remplacer mes scripts, mais il vallait mieux ne pas faire √ßa au build), mais pas leur redimensionnement automatique, il faut impl√©menter soi-m√™me la m√©canique.
Pour pouvoir redimensionner les images √† la vol√©e (au build donc), la meilleure solution semble d'utiliser un hook _img_ Hugo, qui permet de surcharger la traduction du markdown et d'y mettre le code qu'on souhaite.

Le hook utilis√© par d√©faut est le suivant :

```go
<img src="{{ .Destination | safeURL }}"
  {{- with .PlainText }} alt="{{ . }}"{{ end -}}
  {{- with .Title }} title="{{ . }}"{{ end -}}
>
```

Une image d√©clar√©e en Markdown de cette mani√®re :

```markdown
![Une image](photo.jpg)
```

aura pour √©quivalent HTML le code suivant :

```html
<img src="/photo.jpg" alt="Une image">
```

Pour redimensionner les images √† une taille maximale de 820px (la taille utilis√©e sur la colonne de contenu de ce site), j'utilise le hook suivant :

```go
{{- $image := .Page.Resources.GetMatch .Destination -}}

{{- $width := math.Min 820 $image.Width -}}
{{- $resizeOpts := printf "%dx webp q75 lanczos" (int $width) -}}

{{- with $image.Resize $resizeOpts -}}
<img src="{{ .RelPermalink }}" width="{{ .Width }}" height="{{ .Height }}"
    {{- with $.PlainText }} alt="{{ . }}"{{ end -}}
    {{ with $.Title }}title="{{ . }}"{{ end }}>
{{- end -}}
```

La magie a lieu sur les premi√®res lignes.
Je redimensionne l'image √† la taille maximale de 820px (ou moins si l'image est plus petite).

Le HTML g√©n√©r√© par Hugo pour mes images est maintenant le suivant :

```html
<img src="/photo_hu_ed495de5ae801a42.webp" width="820" height="540" alt="Une image">
```

Avec le redimensionnement et la conversion en webp, j'optimise les images pour leur affichage sur le format de mon site, au build, en conservant les images en webp sur leur r√©solution originale.

Je peux m√™me aller encore un peu plus loin en travaillant avec un `srcset` pour proposer au navigateur des images de diff√©rentes tailles en fonction de la taille d'affichage de la vue, ce qui permet de ne pas t√©l√©charger une image de 820 pixels de large pour un affichage qui n'en comporte que 480.

En retravaillant le hook pour g√©n√©rer plusieurs images de dimensions diff√©rentes, j'obtiens le code suivant :

```go
{{- $image := .Page.Resources.GetMatch .Destination -}}

{{- $width820 := math.Min 820 $image.Width -}}
{{- $resizeOpts := printf "%dx webp q75 lanczos" (int $width820) -}}
{{- $img820 := $image.Resize $resizeOpts -}}

{{- $width480 := math.Min 480 $image.Width -}}
{{- $resizeOpts := printf "%dx webp q75 lanczos" (int $width480) -}}
{{- $img480 := $image.Resize $resizeOpts -}}

<img srcset="{{ $img820.RelPermalink }} 820w,
             {{ $img480.RelPermalink }} 480w"
     sizes="(max-width: 480px) 480px,
            820px"
     src="{{ $img820.RelPermalink }}"
 {{- with $.PlainText }} alt="{{ . }}"{{ end -}}
 {{ with $.Title }}title="{{ . }}"{{ end }}>
```

Le code HTML g√©n√©r√© ressemble donc √† √ßa :

```html
<img srcset="/photo_hu_ed495de5ae801a42.webp 820w, 
             /photo_hu_21e26f92cb8d445a.webp 480w"
     sizes="(max-width: 480px) 480px, 
            820px" 
     src="/photo_hu_ed495de5ae801a42.webp"
     alt="Une image">
```

Tr√®s basiquement, je redimensionne les images en 2 tailles, `820px` et `480px`, et je demande au navigateur d'utiliser la version de `480px` pour toutes les tailles d'√©cran inf√©rieures √† `480px` et la version de `820px` pour toutes les autres tailles.

On peut encore aller un peu plus loin, mais on a d√©j√† fait un bon travail sur les images, il est tant de passer √† une √©tape suivante.

> Ces redimensionnements sont donc faits au build, autant dire que chaque article va augmenter le temps de build de mani√®re exponentielle (2 redimensionnements par image).
> Il va probablement falloir que je trouve un autre moyen prochainement, peut-√™tre un petit cache S3, mais c'est un bon d√©but.

## Pr√©-compression des ressources statiques

Les images √©tant maintenant plus l√©g√®res et redimensionn√©es au build par Hugo, je peux m'atteler √† la compression des ressources d√©j√† minifi√©es (HTML, CSS et JS donc).

Avant de passer √† la pr√©-compression en elle-m√™me, il faut regarder comment les ressources seront servies.

Mon site est h√©berg√© chez Clever Cloud, dans une instance de type _static_.
J'avais √©crit un article √† ce sujet l'ann√©e derni√®re : [D√©ployer des applications statiques sur Clever Cloud](/2025/06//2025-06-05-static-apps-clever).

Clever Cloud permet d'utiliser Caddy pour servir les fichiers statiques simplement en ajoutant un `Caddyfile` √† la racine du projet.

Cette option va me permettre de pouvoir configurer Caddy pour servir le r√©pertoire `public` du site :

```Caddyfile
# Clever Cloud needs us to listen on port 8080
:8080

file_server {
	# Clever Cloud serves the public directory
    root public
}

# Ask Caddy to compress static files 
encode
```

Lors de l'ex√©cution d'une requ√™te, Caddy va servir les fichiers statiques, et potentiellement compresser les r√©ponses HTTP en alimentant le headers `Content-Encoding`, gr√¢ce √† la directive `encode`. Les formats utilis√©s par d√©faut par Caddy sont `zstd` et `gzip`, et seules les ressources pertinentes sont compress√©es (les formats d√©j√† compress√©s comme `jpg` ne sont pas re-compress√©s).

Cette compression permet d'√©conomiser de la bande passante et acc√©l√®re le temps de chargement des pages.

Cependant, la compression se fait en utilisant un peu de CPU √† la vol√©e.
Il est alors int√©ressant de pr√©-compresser les ressources statiques √† la phase de build pour √©conomiser un peu de CPU.

Une directive Caddy permet de servir des fichiers statiques pr√©-compress√©s : `precompressed`.
Caddy va alors rechercher des variantes compress√©es des fichiers, sous la forme de fichiers sidecar.
√Ä c√¥t√© de chaque fichier statique, il faut donc g√©n√©rer les variantes compress√©es et les nommer en utilisant les extensions `.gz`, `.br` et `.zst` par exemple.

Hugo ne permet pas de g√©n√©rer ces variantes compress√©es de lui-m√™me, donc je dois utiliser un petit script qui s'ex√©cutera en fin de la phase de build.

J'ai donc cr√©√© un script `precompress` dans mon fichier `mise.toml` :

```toml
[tasks.build]
description = "Build le site avec Hugo"
run = "hugo --gc --minify --destination public"

[tasks.precompress]
description = "Precompress static resources"
run = '''
COMPRESSREGEX=".*(html|css|js|xml|ico|svg|md|pdf)$"
find public/ -type f -regextype egrep -regex $COMPRESSREGEX | xargs zstd --keep --force -19
find public/ -type f -regextype egrep -regex $COMPRESSREGEX | xargs gzip --keep  --force --best
'''
```

J'ai impl√©ment√© la compression avec `gzip` en utilisant le plus haut niveau de compression possible (`--best`), et avec `zstd` avec la plus forte compression √©galement (`-19`). Le niveau de compression a surtout un impact √† la compression, mais peu √† la d√©compression, donc autant maximiser les diff√©rents niveaux.
J'ai fait l'impasse sur le format `br` parce qu'il n√©cessite d'installer un binaire suppl√©mentaire sur mes instances Clever Cloud, et que `gz` et `zst` sont d√©j√† bien suffisants : `zst` sera support√© par les navigateurs modernes dans les versions les plus r√©centes, `gzip` fera office de format par d√©faut raisonnable.

Pour ex√©cuter de script, il suffit d'indiquer √† Clever Cloud d'ex√©cuter `mise run precompress` en tant que hook post-build, avec une variable d'environnement `CC_POST_BUILD_HOOK` :

![Clever Cloud post build hook](clever-post-build-hook.webp)

Le script `precompress` est inspir√© d'un [article de blog de Scott Laird](https://scottstuff.net/posts/2025/03/09/precompressing-content-with-hugo-and-caddy/) sur lequel je suis tomb√© en faisant quelques recherches.
Il recherche l'ensemble des fichiers matchant la regex donn√©e, et utilise `zstd` pour compresser ces fichiers.

L'ex√©cution de ces scripts produit la sortie suivante : 

```bash
[precompress] $ COMPRESSREGEX=".*(html|css|js|xml|ico|svg|md|pdf)$"
245 files compressed : 80.99% (  83.3 MiB =>   67.4 MiB)                       B ==> 98%^T
```

On peut valider que les fichiers build√©s sont pr√©compress√©s comme souhait√©, avec les extensions `.gz` et `.zst` :

```bash
$ ls public/
2020         404.html.zst  fonts           index.xml.zst                           projects
2021         ai            fr              js                                      robots.txt
2022         ai-manifesto  icons           logo_blue.png                           series
2023         books         images          logo_transparent_background.png         sitemap.xml
2024         credentials   index.html      now                                     sitemap.xml.gz
2025         css           index.html.gz   page                                    sitemap.xml.zst
2026         ekite         index.html.zst  posts                                   stats
404.html     en            index.xml       pp_ekite_itvw.png                       tags
404.html.gz  favicon.png   index.xml.gz    pp_ekite_itvw_hu_41404e93ad715bdf.webp  talks
```

et v√©rifier la taille des fichiers compress√©s :

```bash
$ ls -al public/index.*
.rw-rw-r-- jwittouck jwittouck  33 KB Wed Feb 11 12:15:21 2026 index.html
.rw-rw-r-- jwittouck jwittouck 9.4 KB Wed Feb 11 12:15:21 2026 index.html.gz
.rw-rw-r-- jwittouck jwittouck 9.0 KB Wed Feb 11 12:15:21 2026 index.html.zst
.rw-rw-r-- jwittouck jwittouck  67 KB Wed Feb 11 12:15:22 2026 index.xml
.rw-rw-r-- jwittouck jwittouck  18 KB Wed Feb 11 12:15:22 2026 index.xml.gz
.rw-rw-r-- jwittouck jwittouck  17 KB Wed Feb 11 12:15:22 2026 index.xml.zst
```

> On a encore un joli gain avec les compressions `gzip` et `zstd`, de l'ordre de 75%.

Pour ensuite servir les fichiers pr√©compress√©s, il faut ajouter la [directive `precompressed`](https://caddyserver.com/docs/caddyfile/directives/file_server#precompressed) dans le `Caddyfile` :

```Caddyfile
# Clever Cloud needs us to listen on port 8080
:8080

file_server {
	# Clever Cloud serves the public directory
    root public
    # serve precompressed files
    precompressed
}

# Ask Caddy to compress static files 
encode
```

La directive `precompressed` recherchera dans l'ordre les fichiers `.zst` et `.gz` pour les servir en priorit√©, et utilisera comme _fallback_ une compression √† la vol√©e.

On peut ensuite simplement v√©rifier que les fichiers compress√©s sont bien servis compress√©s avec une commande `curl`.

Voici ce qui √©tait renvoy√© _avant_ la compression :

```bash
$ curl --head https://codeka.io

Content-Length: 34963
Content-Type: text/html; charset=utf-8
Server: Caddy
```

et la m√™me commande apr√®s la compression :

```bash
$ curl --compressed --head https://codeka.io

HTTP/1.1 200 OK
Content-Encoding: zstd
Content-Type: text/html; charset=utf-8
Server: Caddy
Content-Length: 9
```

On passe d'une page HTML de 34ko √† une donn√©e compress√©e de 9ko, sans impacter le CPU du serveur puisque la compression se fait au build !

## Headers de s√©curit√©

La derni√®re √©tape de cette configuration consiste √† moderniser les headers servis pour impl√©menter un peu de s√©curit√© suppl√©mentaire.

Maintenant que Caddy sert le site et que j'ai un `Caddyfile` sur lequel j'ai la main, je peux contr√¥ler les headers HTTP renvoy√©s facilement.

Pour savoir quoi-faire, sur les conseils d'Antoine, j'ai utilis√© l'analyseur du [MDN Observatory](https://developer.mozilla.org/en-US/observatory)¬†:

Voici mon score, encore une fois peu flatteur¬†:

![R√©sultat de l'analyse de MDN](mdn-analysis.webp "R√©sultat de l'analyse de MDN")

> Encore une fois, le r√©sultat de l'analyse est m√©diocre, puisqu'aucune optimisation n'avait √©t√© faite. Il y a du travail sur cette partie !

### HSTS et headers faciles

Le premier header int√©ressant √† utiliser est le `Strict-Transport-Security`.

Ce header a pour effet de forcer les navigateurs √† utiliser HTTPS.
Bien que j'ai d√©j√† configur√© une redirection HTTP vers HTTPS sur mon domaine avec Clever Cloud, c'est une mesure de s√©curit√© suppl√©mentaire.

La recommandation de MDN est de positionner cette valeur :

```text
Strict-Transport-Security: max-age=63072000
```

Dans mon Caddyfile, rien de plus simple, j'ajoute le header `Strict-Transport-Security` :

```Caddyfile
# Clever Cloud needs us to listen on port 8080
:8080

file_server {
	# Clever Cloud serves the public directory
    root public
    precompressed
}

# Custom headers for security
header {
	Strict-Transport-Security "max-age=63072000"
    X-Content-Type-Options nosniff
}

# Ask Caddy to compress static files 
encode
```

Je fais la m√™me chose pour le header `X-Content-Type-Options`, qui permet d'√©viter en substance qu'une balise `style` charge autre chose que du CSS.

### Content-Security-Policy

Ce header, un peu plus complexe √† mettre en ≈ìuvre, indique au navigateur quelle politique de s√©curit√© appliquer √† l'ex√©cution des scripts provenant de sources externes au site web.
C'est une mesure de s√©curit√© permettant de se pr√©munir des injections de type XSS (Cross-Site Scripting).

Le header doit d√©clarer l'ensemble des sources (domaines) accept√©s pour le chargement des scripts, styles, images et autres ressources.
Utiliser ce header a aussi pour effet de d√©sactiver le CSS et le JS "inline", ce qui est plut√¥t une bonne pratique.

Apr√®s avoir supprim√© tous les styles inlines de mon site, j'ai configur√© le header dans mon Caddyfile :

```Caddyfile
# Clever Cloud needs us to listen on port 8080
:8080

file_server {
	# Clever Cloud serves the public directory
    root public
    precompressed
}

# Custom headers for security
header {
	Strict-Transport-Security "max-age=63072000"
	X-Content-Type-Options nosniff
	
	Content-Security-Policy "
	    script-src 'self' codeka.io plausible.io;
	    connect-src 'self' codeka.io plausible.io;
	    
	    frame-src 'self' plausible.io www.youtube-nocookie.com openfeedback.io;
	    frame-ancestors 'none';
	    
	    img-src 'self' img.shields.io;
	    
	    default-src 'self';
	"
}

# Ask Caddy to compress static files 
encode
```

Pour les directives `script-src` et `connect-src`, √©tant donn√© que j'utilise plausible.io pour suivre les visites de mes articles, son script doit pouvoir √™tre charg√©, et ouvrir des connexions sortantes. De la m√™me mani√®re, j'ai des iframes (bouh) sur les pages de mes talks qui r√©f√©rencent les videos Youtube ainsi que les feedbacks OpenFeedback.io. Je dois donc aussi autoriser ces ressources, avec la directive `frame-src`. La directive `frame-ancestor` bloque l'utilisation de mon site dans une iframe externe (ce n'√©tait pas tout √† fait n√©cessaire, mais √ßa ne co√ªte pas grand chose de l'ajouter).
La directive `img-src` permet d'autoriser les images qui proviennent de shields.io, que j'utilise pour afficher quelques badges.
Enfin, la directive `default-src` sert de fallback pour toutes les directives possibles, et indique que seul mon site est une source autoris√©e. 

## Et √ßa donne quoi ?

Apr√®s toutes ces modifications, voici les r√©sultats de l'analyse LightHouse :

Voici les scores de mon site √† l'heure actuelle, pour une navigation mobile et desktop :

![Score Lighthouse pour un mobile](lighthouse-mobile-after.webp)
![Score Lighthouse pour un desktop](lighthouse-desktop-after.webp)
{ class="images-grid-2" }

96 et 100 en performance sur la page d'accueil, on est mieux que les 91 initiaux, mission accomplie ici.

Pour la page qui avait un r√©sultat vraiment mauvais, le r√©sultat est un peu plus mitig√© :

![Score Lighthouse sur mobile pour une autre page](lighthouse-talk-mobile-after.webp)
![Score Lighthouse sur desktop pour une autre page](lighthouse-talk-desktop-after.webp)
{ class="images-grid-2" }

Les scores initiaux √©taient de 43 en mobile et de 58 en desktop.
En fouillant un peu, ce sont les `iframes` qui plombent les perfs, donc je n'y pourrai pas grand chose.

C√¥t√© headers de s√©curit√©, j'ai atteint la perfection avec le joli score de 105/100, soit un A+, √† la place du D- initial :

![Le d√©tail du score MDN A+](mdn-after.webp)

## Conclusion

√áa m'a pris une bonne demi-journ√©e pour mettre en place tous ces m√©canismes, mais j'en ressors avec une meilleure compr√©hension de la s√©curit√© et de la compression en HTTP.
J'ai aussi d√©couvert Caddy, et am√©lior√© mon fichier `mise.toml`.

Et le r√©sultat n'est pas des moindres. L'optimisation est r√©elle (m√™me si je n'ai pas pris le temps de tout mesurer pr√©cis√©ment).

Pour la plupart de mes lecteurs, l'impact de la compression sera probablement minime, car sur des r√©seaux performants, la diff√©rence de temps de chargement ne se ressentira peut-√™tre pas beaucoup.
Mais avec une compression effectu√©e uniquement au build, c'est aussi une du CPU de moins de consomm√©, ce qui devrait pouvoir m'assurer de rester sur des instances les plus petites pour mon site le plus longtemps possible.

Il me restera √† adresser le sujet du temps de build, qui risque de poser probl√®me √† terme. Je testerai peut-√™tre une architecture avec un petit cache Varnish devant un bucket.

## Liens et r√©f√©rences

* Documentation de Hugo :
  * Configuration de l'[optimisation des images avec Hugo](https://gohugo.io/configuration/imaging/#quality)
  * La [m√©thode Resize de Hugo](https://gohugo.io/methods/resource/resize/)
  * Les [formats support√©s par Hugo](https://gohugo.io/functions/images/process/#format)
  * [Le hookimage de Hugo](https://gohugo.io/render-hooks/images/#article)

* Documentation de Caddy :
  * [La directive `encode`](https://caddyserver.com/docs/caddyfile/directives/encode#syntax)
  * [La directive `precompressed`](https://caddyserver.com/docs/caddyfile/directives/file_server#precompressed)

* Documentation MDN :
  * [Responsive Images](https://developer.mozilla.org/en-US/docs/Web/HTML/Guides/Responsive_images)  
  * [MDN HTTP Observatory](https://developer.mozilla.org/en-US/observatory)
  * [Content-Security-Policy](https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Content-Security-Policy)
  * [HTTP Strict Transport Security implementation](https://developer.mozilla.org/en-US/docs/Web/Security/Practical_implementation_guides/TLS#http_strict_transport_security_implementation)
  * [MIME type verification](https://developer.mozilla.org/en-US/docs/Web/Security/Practical_implementation_guides/MIME_types)

* [Precompressing Content With Hugo and Caddy](https://scottstuff.net/posts/2025/03/09/precompressing-content-with-hugo-and-caddy/)

* L'excellent talk de Antoine Caron et Hubert Sabloni√®re : [La compression Web : comment (re)prendre le contr√¥le ?](https://www.youtube.com/watch?v=LWd0hr6ljZk)

* L'article de Denis Germain, qui a fait la m√™me chose que moi cette semaine : [Optimisation webperf : AVIF et pr√©-compression pour le blog](https://blog.zwindler.fr/2026/02/19/optimisation-webperf-avif-precompression/)
